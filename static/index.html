<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI-Sight</title>
    <script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"></script>
  </head>
  <body class="h-screen w-screen overflow-hidden relative">
    <video
      id="webcam"
      autoplay
      playsinline
      class="absolute top-0 left-0 w-screen h-screen object-cover -z-10"></video>

    <div class="max-w-md m-auto h-screen relative">
      <header
        class="absolute top-0 left-0 w-full px-6 py-4 flex justify-between items-center z-50">
        <!-- Left icon -->
        <button class="w-14 h-14">
          <!-- Replace with your Discord icon (e.g., from Lucide, Heroicons, or SVG) -->
          <!-- <svg xmlns="http://www.w3.org/2000/svg" class="w-8 h-8" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 10h.01M12 10h.01M16 10h.01M9 16h6" />
          </svg> -->
        </button>

        <!-- Center logo -->
        <div
          class="bg-[#34464D] px-8 py-3 rounded-[20px] border-2 border-white">
          <h1 class="text-white text-3xl font-bold">AI-Sight</h1>
        </div>

        <!-- Right icon -->
        <button
          class="w-14 h-14 flex items-center justify-center rounded-full border-2 border-white text-white">
          <!-- Info icon -->
          <svg
            xmlns="http://www.w3.org/2000/svg"
            class="w-8 h-8"
            fill="none"
            viewBox="0 0 24 24"
            stroke="currentColor">
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M13 16h-1v-4h-1m1-4h.01M12 12h.01M12 16h.01" />
          </svg>
        </button>
      </header>

      <div
        class="absolute inset-0 -top-[20%] flex items-center justify-center pointer-events-none">
        <div class="w-[300px] h-[300px] relative">
          <!-- Top-left -->
          <div
            class="absolute top-0 left-0 w-10 h-10 border-t-4 border-l-4 border-white rounded-tl-[40px]"></div>
          <!-- Top-right -->
          <div
            class="absolute top-0 right-0 w-10 h-10 border-t-4 border-r-4 border-white rounded-tr-[40px]"></div>
          <!-- Bottom-left -->
          <div
            class="absolute bottom-0 left-0 w-10 h-10 border-b-4 border-l-4 border-white rounded-bl-[40px]"></div>
          <!-- Bottom-right -->
          <div
            class="absolute bottom-0 right-0 w-10 h-10 border-b-4 border-r-4 border-white rounded-br-[40px]"></div>
        </div>
      </div>

      <button
        id="recordButton"
        class="absolute inset-x-1/2 -translate-x-1/2 bottom-14 w-[80%] h-40 px-3 py-2 bg-white rounded-2xl shadow-black">
        Hold to Record Audio & Video
      </button>
    </div>

    <script>
      // WebSocket and state management
      let socket = null;
      let isConnected = false;
      let mediaStream = null;
      let audioContext = null;
      let audioProcessor = null;
      let webcamInterval = null;
      let isRecording = false;

      // Audio playback management
      let audioQueue = [];
      let isPlaying = false;
      let playbackAudioContext = null;
      let audioBufferSource = null;
      let audioAnalyser = null;
      let visualizationInterval = null;
      let currentAudioEndTime = 0;
      let audioChunks = [];

      // DOM elements
      const connectionStatus = document.getElementById("connectionStatus");
      // const cameraStatus = document.getElementById("cameraStatus");
      const recordButton = document.getElementById("recordButton");
      const sendTextBtn = document.getElementById("sendText");
      const textInput = document.getElementById("textInput");
      const responseText = document.getElementById("responseText");
      const webcamVideo = document.getElementById("webcam");
      const audioContainer = document.getElementById("audioContainer");
      const audioVisualizer = document.getElementById("audioVisualizer");

      async function requestMediaPermissions() {
        try {
          await navigator.mediaDevices.getUserMedia({
            video: true,
            audio: true,
          });
          console.log("Permissions granted for camera and microphone");
        } catch (error) {
          console.error("Permissions denied:", error);
          alert(
            "Please allow access to your camera and microphone to use this app."
          );
        }
      }

      // Initialize camera preview
      async function initCameraPreview() {
        try {
          mediaStream = await navigator.mediaDevices.getUserMedia({
            audio: false,
            video: {
              facingMode: "environment",
            },
          });
          webcamVideo.srcObject = mediaStream;
          // cameraStatus.textContent = "Camera active (preview only)";
        } catch (error) {
          console.error("Error initializing camera preview:", error);
          // cameraStatus.textContent = "Camera error: " + error.message;
        }
      }

      // Connect to WebSocket
      async function connectWebSocket() {
        if (isConnected) return;

        try {
          const protocol =
            window.location.protocol === "https:" ? "wss:" : "ws:";
          socket = new WebSocket(`${protocol}//${window.location.host}/ws`);

          socket.onopen = () => {
            isConnected = true;
          };

          socket.onclose = () => {
            isConnected = false;
            setTimeout(connectWebSocket, 3000);
          };

          socket.onerror = (error) => {
            console.error("WebSocket error:", error);
          };

          socket.onmessage = async (event) => {
            // Handle binary audio data
            if (event.data instanceof Blob) {
              try {
                const arrayBuffer = await event.data.arrayBuffer();
                handleAudioData(arrayBuffer);
              } catch (error) {
                console.error("Blob processing error:", error);
              }
            } else if (event.data instanceof ArrayBuffer) {
              handleAudioData(event.data);
            }
            // Handle text messages
            else if (typeof event.data === "string") {
              try {
                const message = JSON.parse(event.data);
                if (message.type === "text") {
                  responseText.innerHTML += `<p>${message.data}</p>`;
                  responseText.scrollTop = responseText.scrollHeight;
                }
              } catch (e) {
                console.error("Message parsing error:", e);
              }
            }
          };
        } catch (error) {
          console.error("Error connecting to WebSocket:", error);
          setTimeout(connectWebSocket, 3000);
        }
      }

      function handleAudioData(arrayBuffer) {
        // Convert to the correct audio format
        const audioData = convertAudioDataIfNeeded(arrayBuffer);

        // Queue the audio data
        audioQueue.push(audioData);

        // Start playback if we have enough buffered chunks
        const MIN_BUFFERED_CHUNKS = 3;
        if (audioQueue.length >= MIN_BUFFERED_CHUNKS && !isPlaying) {
          processAudioQueue();
        }

        // Update buffering state
      }

      function convertAudioDataIfNeeded(buffer) {
        // Check if the buffer has a WAV header
        const header = new Uint8Array(buffer, 0, 4);
        const isWav =
          header[0] === 0x52 &&
          header[1] === 0x49 &&
          header[2] === 0x46 &&
          header[3] === 0x46;

        if (isWav) {
          return buffer;
        }

        // Convert raw PCM to WAV format
        return encodeRawPCMAsWAV(buffer, 1, 24000);
      }

      function encodeRawPCMAsWAV(buffer, numChannels, sampleRate) {
        const bytesPerSample = 2;
        const blockAlign = numChannels * bytesPerSample;
        const byteRate = sampleRate * blockAlign;
        const dataSize = buffer.byteLength;
        const fileSize = 36 + dataSize;

        const wavHeader = new ArrayBuffer(44);
        const view = new DataView(wavHeader);

        // Write WAV header
        writeString(view, 0, "RIFF");
        view.setUint32(4, fileSize, true);
        writeString(view, 8, "WAVE");
        writeString(view, 12, "fmt ");
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, byteRate, true);
        view.setUint16(32, blockAlign, true);
        view.setUint16(34, 16, true);
        writeString(view, 36, "data");
        view.setUint32(40, dataSize, true);

        // Combine header and PCM data
        const wavBuffer = new Uint8Array(
          wavHeader.byteLength + buffer.byteLength
        );
        wavBuffer.set(new Uint8Array(wavHeader), 0);
        wavBuffer.set(new Uint8Array(buffer), wavHeader.byteLength);

        return wavBuffer.buffer;
      }

      function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      }

      async function processAudioQueue() {
        if (audioQueue.length === 0) {
          isPlaying = false;
          currentAudioEndTime = 0;
          return;
        }

        // Don't start new playback if previous audio hasn't finished
        const now = playbackAudioContext ? playbackAudioContext.currentTime : 0;
        if (now < currentAudioEndTime) {
          return;
        }

        isPlaying = true;

        try {
          // Initialize audio context if needed
          if (!playbackAudioContext) {
            playbackAudioContext = new (window.AudioContext ||
              window.webkitAudioContext)({
              sampleRate: 24000,
            });

            audioAnalyser = playbackAudioContext.createAnalyser();
            audioAnalyser.fftSize = 64;
          }

          // Get the next chunk of audio
          const audioData = audioQueue.shift();

          // Decode the audio data
          const audioBuffer = await playbackAudioContext.decodeAudioData(
            audioData
          );
          const duration = audioBuffer.duration;

          // Create and configure audio source
          if (audioBufferSource) {
            audioBufferSource.stop();
            audioBufferSource.disconnect();
          }

          audioBufferSource = playbackAudioContext.createBufferSource();
          audioBufferSource.buffer = audioBuffer;

          // Connect to analyzer and destination
          audioBufferSource.connect(audioAnalyser);
          audioAnalyser.connect(playbackAudioContext.destination);

          // Schedule playback with precise timing
          const startTime = Math.max(
            playbackAudioContext.currentTime,
            currentAudioEndTime
          );
          audioBufferSource.start(startTime);
          currentAudioEndTime = startTime + duration;

          // When this chunk finishes, play the next one
          audioBufferSource.onended = () => {
            setTimeout(() => {
              processAudioQueue();
            }, 30); // Small delay between chunks
          };
        } catch (error) {
          console.error("Audio playback error:", error);
          setTimeout(() => {
            processAudioQueue();
          }, 100);
        }
      }
      // Start media recording
      async function startMediaRecording() {
        if (isRecording) return;

        try {
          isRecording = true;
          recordButton.classList.add("recording");
          // cameraStatus.textContent = "Recording audio & video...";

          // Add audio to media stream
          const audioStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              echoCancellation: true,
              noiseSuppression: true,
              sampleRate: 16000,
            },
            video: false,
          });

          // Set up audio processing
          audioContext = new (window.AudioContext || window.webkitAudioContext)(
            {
              sampleRate: 16000,
            }
          );

          const source = audioContext.createMediaStreamSource(audioStream);
          audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);

          // Process audio chunks
          audioProcessor.onaudioprocess = (event) => {
            if (
              !isRecording ||
              !isConnected ||
              !socket ||
              socket.readyState !== WebSocket.OPEN
            )
              return;

            const inputData = event.inputBuffer.getChannelData(0);
            const pcmData = new Int16Array(inputData.length);
            for (let i = 0; i < inputData.length; i++) {
              pcmData[i] = Math.max(
                -32768,
                Math.min(32767, inputData[i] * 32767)
              );
            }

            try {
              socket.send(
                JSON.stringify({
                  type: "audio",
                  data: Array.from(pcmData),
                  sampleRate: audioContext.sampleRate,
                })
              );
            } catch (error) {
              console.error("Error sending audio:", error);
            }
          };

          source.connect(audioProcessor);
          audioProcessor.connect(audioContext.destination);

          // Send video frames periodically
          webcamInterval = setInterval(() => {
            if (!isRecording || !isConnected) return;

            try {
              const canvas = document.createElement("canvas");
              canvas.width = webcamVideo.videoWidth;
              canvas.height = webcamVideo.videoHeight;
              const ctx = canvas.getContext("2d");
              ctx.drawImage(webcamVideo, 0, 0, canvas.width, canvas.height);

              canvas.toBlob(
                (blob) => {
                  const reader = new FileReader();
                  reader.onload = () => {
                    const base64data = reader.result.split(",")[1];
                    socket.send(
                      JSON.stringify({
                        type: "image",
                        data: base64data,
                      })
                    );
                  };
                  reader.readAsDataURL(blob);
                },
                "image/jpeg",
                0.7
              );
            } catch (error) {
              console.error("Error capturing webcam frame:", error);
            }
          }, 500);
        } catch (error) {
          console.error("Error starting media recording:", error);
          stopMediaRecording();
        }
      }

      // Stop media recording
      function stopMediaRecording() {
        if (!isRecording) return;

        isRecording = false;
        recordButton.classList.remove("recording");
        // cameraStatus.textContent = "Camera active (preview only)";

        if (audioProcessor) {
          audioProcessor.disconnect();
          audioProcessor = null;
        }

        if (mediaStream) {
          mediaStream.getAudioTracks().forEach((track) => track.stop());
        }

        if (webcamInterval) {
          clearInterval(webcamInterval);
          webcamInterval = null;
        }

        if (
          mediaStream &&
          !mediaStream
            .getVideoTracks()
            .some((track) => track.readyState === "live")
        ) {
          initCameraPreview();
        }
      }

      // Clean up audio playback
      function cleanupAudioPlayback() {
        if (audioBufferSource) {
          audioBufferSource.stop();
          audioBufferSource.disconnect();
          audioBufferSource = null;
        }
        if (playbackAudioContext) {
          playbackAudioContext
            .close()
            .catch((e) => console.log("AudioContext close error:", e));
          playbackAudioContext = null;
        }
        audioQueue = [];
        isPlaying = false;
        currentAudioEndTime = 0;
      }

      // Send text message
      function sendTextMessage() {
        const text = textInput.value.trim();
        if (text && socket && socket.readyState === WebSocket.OPEN) {
          socket.send(
            JSON.stringify({
              type: "text",
              data: text,
            })
          );
          textInput.value = "";
        }
      }

      // Event listeners
      recordButton.addEventListener("mousedown", startMediaRecording);
      recordButton.addEventListener("mouseup", stopMediaRecording);
      recordButton.addEventListener("mouseleave", stopMediaRecording);

      recordButton.addEventListener("touchstart", (e) => {
        e.preventDefault();
        startMediaRecording();
      });

      recordButton.addEventListener("touchend", (e) => {
        e.preventDefault();
        stopMediaRecording();
      });

      // sendTextBtn.addEventListener("click", sendTextMessage);
      // textInput.addEventListener("keypress", (e) => {
      //   if (e.key === "Enter" && !e.shiftKey) {
      //     e.preventDefault();
      //     sendTextMessage();
      //   }
      // });

      // Handle page visibility changes
      document.addEventListener("visibilitychange", () => {
        if (document.hidden) {
          stopMediaRecording();
          cleanupAudioPlayback();
        }
      });

      window.addEventListener("DOMContentLoaded", async () => {
        await requestMediaPermissions();
        await initCameraPreview(); // optionally start the preview immediately
        connectWebSocket(); // or any other setup
      });
    </script>
  </body>
</html>
